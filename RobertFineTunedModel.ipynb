{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f9825dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7ec848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e3e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "841ac09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ace212e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e28b8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('deepset/roberta-base-squad2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/roberta-base-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ec9fe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForQuestionAnswering(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acc52985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "161747be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/Users/shashwatbindal/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SQuAD dataset\n",
    "dataset = load_dataset(\"squad\", \"plain_text\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f4858fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_features = []\n",
    "\n",
    "for example in dataset:\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    context = example[\"context\"]\n",
    "    questions = example[\"question\"]\n",
    "    answers = example[\"answers\"]\n",
    "    answer_start=0\n",
    "    answer_end=0\n",
    "    tokenized_context = tokenizer.tokenize(context)\n",
    "    tokenized_question = tokenizer.tokenize(questions)\n",
    "    tokenized_input = [\"[CLS]\"] + tokenized_question + [\"[SEP]\"] + tokenized_context + [\"[SEP]\"]\n",
    "    inputs = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
    "    char_to_token = []\n",
    "    token_index = 1  # Skip the [CLS] token\n",
    "    for char_index, char in enumerate(context):\n",
    "            if char != \" \" and char != \"\\n\":\n",
    "                char_to_token.append(token_index)\n",
    "            if token_index < len(tokenized_input) - 1 and char_index + 1 < len(tokenized_input[token_index]):\n",
    "                token_index += 1\n",
    "\n",
    "    for answer in answers[\"answer_start\"]:\n",
    "        answer_start = answer\n",
    "        token_start = char_to_token[min(answer_start, len(char_to_token) - 1)]\n",
    "        token_start = min(token_start, len(inputs) - 1)\n",
    "        start_positions.append(token_start)\n",
    "\n",
    "\n",
    "\n",
    "    for text in answers[\"text\"]:\n",
    "        answer_end = answer_start + len(text) - 1\n",
    "        token_end = char_to_token[min(answer_end, len(char_to_token) - 1)]\n",
    "        token_end = min(token_end, len(inputs) - 1)\n",
    "        end_positions.append(token_end)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "161e7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.append(\n",
    "            {\n",
    "                \"input_ids\": inputs,\n",
    "                \"attention_mask\": [1] * len(inputs),\n",
    "                \"start_positions\": start_positions,\n",
    "                \"end_positions\": end_positions,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f80b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wrapt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d846d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import  AdamW\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from transformers import AdamW\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the batch size and number of training epochs\n",
    "batch_size = 4\n",
    "num_epochs =50\n",
    "\n",
    "# Convert the train_features list to a PyTorch DataLoader\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor([f[\"input_ids\"] for f in train_features], dtype=torch.long),\n",
    "    torch.tensor([f[\"attention_mask\"] for f in train_features], dtype=torch.long),\n",
    "    torch.tensor([f[\"start_positions\"] for f in train_features], dtype=torch.long),\n",
    "    torch.tensor([f[\"end_positions\"] for f in train_features], dtype=torch.long),\n",
    ")\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Load the pre-trained BERT model for question answering\n",
    "# model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('deepset/roberta-base-squad2')\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer and learning rate\n",
    "# optimizer = AdamW(model.parameters(), lr=3e-6)\n",
    "optimizer = optim.Adamax(model.parameters(), lr=9e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a642970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, start_positions, end_positions = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4812dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/shashwatbindal/Fine_Tuned_modelRobert\"\n",
    "\n",
    "# Save the fine-tuned model\n",
    "# model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdfdb01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is coronary artery disease  ?\n",
      "Predicted Answer:  when the arteries that supply blood to the heart become narrowed or blocked\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "\n",
    "# Load the fine-tuned BERT model\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(save_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/roberta-base-squad2')\n",
    "\n",
    "# Prepare the input\n",
    "question = \"what is coronary artery disease  ?\"\n",
    "context = \"\"\"Heart surgery, also known as cardiac surgery, is a complex and intricate procedure performed on the heart to treat a variety of conditions. It is a critical and highly specialized field of medicine that requires a skilled team of healthcare professionals, including cardiac surgeons, anesthesiologists, nurses, and other support staff.\n",
    "\n",
    "There are various types of heart surgeries performed depending on the specific condition being treated. Some common types include coronary artery bypass grafting (CABG), valve replacement or repair, congenital heart defect repairs, and heart transplant.\n",
    "\n",
    "Coronary artery bypass grafting (CABG) is one of the most common heart surgeries. It is performed to treat coronary artery disease, which occurs when the arteries that supply blood to the heart become narrowed or blocked. During this procedure, the surgeon takes a healthy blood vessel from another part of the body, usually the leg or chest, and grafts it onto the blocked coronary artery. This bypasses the blockage and restores blood flow to the heart.\n",
    "\n",
    "Valve replacement or repair is another type of heart surgery. It is performed to treat diseased or damaged heart valves. Heart valves are responsible for ensuring proper blood flow through the heart chambers. When valves become narrowed or leaky, they can impair the heart's ability to pump blood effectively. During valve replacement surgery, the damaged valve is removed and replaced with a mechanical valve or a biological tissue valve. In some cases, the valve can be repaired rather than replaced.\"\"\"\n",
    "inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Process the logits to obtain the predicted answer span\n",
    "start_index = torch.argmax(start_logits)\n",
    "end_index = torch.argmax(end_logits)\n",
    "\n",
    "# Decode the predicted answer span\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n",
    "answer = tokenizer.convert_tokens_to_string(all_tokens[start_index:end_index+1])\n",
    "\n",
    "# Print the predicted answer\n",
    "print(\"Question:\", question)\n",
    "print(\"Predicted Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e03da143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def robert_question_answer(tokenizer, model,question, context, max_len=2000):\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits)\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][start_index:end_index + 1]))\n",
    "    return answer.strip()\n",
    "\n",
    "def split_passage_and_process(tokenizer, model, question, passage, max_len=10000, chunk_size=500):\n",
    "    # Split the passage into smaller chunks\n",
    "    passage_chunks = textwrap.wrap(passage, width=chunk_size)\n",
    "\n",
    "    answers = []\n",
    "    # Process each chunk separately\n",
    "    for chunk in passage_chunks:\n",
    "        answer = robert_question_answer(tokenizer, model, question, chunk, max_len=max_len)\n",
    "        if answer != \"Sorry!, I could not find an answer in the passage.\":\n",
    "            answers.append(answer)\n",
    "\n",
    "    # Combine the answers from all chunks\n",
    "    combined_answer = \" \".join(answers)\n",
    "    return combined_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d395ecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/Users/shashwatbindal/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned BERT model\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(save_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/roberta-base-squad2')\n",
    "\n",
    "# Load the SQuAD validation dataset\n",
    "datasetv = load_dataset(\"squad\", \"plain_text\", split=\"validation[:500]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30c391b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasetv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c74af8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the fine-tuned BERT model\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(save_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/roberta-base-squad2')\n",
    "# # Prepare the input\n",
    "\n",
    "\n",
    "def generate_predictions(dataset, tokenizer, model):\n",
    "    predictions = []\n",
    "    for example in dataset:\n",
    "        inputs = tokenizer.encode_plus(example[\"question\"], example[\"context\"], add_special_tokens=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            start_logits = outputs.start_logits\n",
    "            end_logits = outputs.end_logits\n",
    "\n",
    "        start_index = torch.argmax(start_logits)\n",
    "        end_index = torch.argmax(end_logits)\n",
    "\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][start_index:end_index + 1]))\n",
    "        predictions.append(answer.strip())\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf318bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generate_predictions(datasetv, tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac5665e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_answers=[]\n",
    "for ans in datasetv:\n",
    "    true_answers.append(ans[\"answers\"][\"text\"])\n",
    "    # print(ans[\"answers\"][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef81afd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['golden anniversary',\n",
       "  'February 7, 2016',\n",
       "  'American Football Conference',\n",
       "  'golden anniversary',\n",
       "  'American Football Conference'],\n",
       " [['\"golden anniversary\"', 'gold-themed', '\"golden anniversary'],\n",
       "  ['February 7, 2016', 'February 7', 'February 7, 2016'],\n",
       "  ['American Football Conference',\n",
       "   'American Football Conference',\n",
       "   'American Football Conference'],\n",
       "  ['\"golden anniversary\"', 'gold-themed', 'gold'],\n",
       "  ['American Football Conference',\n",
       "   'American Football Conference',\n",
       "   'American Football Conference']])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[5:10],true_answers[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc4c7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# Set the audio settings\n",
    "sample_rate = 44100\n",
    "duration = 6 # Duration in seconds\n",
    "# output_file = \"audio.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4ba2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f904adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askquestion(audio_file,output_file):\n",
    "    print(\"Recording audio...\")\n",
    "    audio = sd.rec(int(sample_rate * duration), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()\n",
    "\n",
    "    # Save the audio to a file\n",
    "    sf.write(output_file, audio, sample_rate)\n",
    "\n",
    "    print(f\"Audio saved to {output_file}\")\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    # Path to the audio file\n",
    "\n",
    "    # Load the audio file\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        # Read the audio data\n",
    "        audio = r.record(source)\n",
    "    text=\"\"    \n",
    "\n",
    "    try:\n",
    "        # Recognize speech from the audio\n",
    "        text = r.recognize_google(audio)\n",
    "        print(\"Transcription:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0458f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "def text_to_speech(text, output_file):\n",
    "    # Create a gTTS object with the text and desired language\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "\n",
    "    # Save the audio to a file\n",
    "    tts.save(output_file)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "output_file = \"output.mp3\"\n",
    "\n",
    "# text_to_speech(text, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32d7c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "def play_mp3(file_path):\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(file_path)\n",
    "    pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1154a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Passageready():\n",
    "\n",
    "    output_file2=\"passage.mp3\"\n",
    "    text_to_speech(\"Give the passage you want to ask questions from\", output_file2)\n",
    "    play_mp3(output_file2)\n",
    "    passage=input(\"Enter the Passage: \")\n",
    "    return passage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4f0fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuestionAnswer(passage):\n",
    "    \n",
    "    output_file=\"Ask.mp3\"\n",
    "    text_to_speech(\"Ask the question\", output_file)\n",
    "    play_mp3(output_file)\n",
    "    question=askquestion(\"question.wav\",\"question.wav\")\n",
    "    ans  = robert_question_answer( tokenizer, model,question, passage)\n",
    "    output_file3=\"answer.mp3\"\n",
    "    text_to_speech(\"The Answer to the question....: \"+question+\"...\"+\"is....:\"+ans+\"...\", output_file3)\n",
    "    play_mp3(output_file3)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "429dfb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi shashwat is good'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage=Passageready()\n",
    "passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "447f95ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Audio saved to question.wav\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Transcription: how is Shashwat\n"
     ]
    }
   ],
   "source": [
    "ans=QuestionAnswer(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3618f15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi i am shashwat'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93a4199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed9bee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e15b97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96c2a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pytesseract\n",
    "\n",
    "# # Load the image using OpenCV\n",
    "# image = cv2.imread('/Users/shashwatbindal/Downloads/WhatsApp Image 2023-06-15 at 13.42.55.jpeg')\n",
    "\n",
    "# # Preprocess the image (if required)\n",
    "# # Apply any necessary preprocessing techniques such as resizing, noise removal, etc.\n",
    "\n",
    "# # Perform OCR using Tesseract\n",
    "# text = pytesseract.image_to_string(image)\n",
    "\n",
    "# # Save the extracted text to a text file\n",
    "# with open('output.txt', 'w') as file:\n",
    "#     file.write(text)\n",
    "\n",
    "# print('Text extracted and saved to output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b0be136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "  ['Carolina Panthers', 'Carolina Panthers', 'Carolina Panthers'],\n",
       "  ['Santa Clara, California',\n",
       "   \"Levi's Stadium\",\n",
       "   \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
       "  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "  ['gold', 'gold', 'gold']],\n",
       " ['Denver Broncos',\n",
       "  'Carolina Panthers',\n",
       "  \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California\",\n",
       "  'Denver Broncos',\n",
       "  'gold'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_answers[:5],predictions[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79f4183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match score: 0.882\n"
     ]
    }
   ],
   "source": [
    "exact_match_count = 0\n",
    "total_examples = len(true_answers)\n",
    "\n",
    "for true_answer, prediction in zip(true_answers, predictions):\n",
    "    if prediction in true_answer:\n",
    "        exact_match_count += 1\n",
    "\n",
    "exact_match_score = exact_match_count / total_examples\n",
    "\n",
    "# Print the exact match score\n",
    "print(\"Exact match score:\", exact_match_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourQuestionAnsweringModel:\n",
    "    def __init__(self):\n",
    "        self.passage = \"\"\n",
    "\n",
    "    def get_passage(self):\n",
    "        output_file = \"passage.mp3\"\n",
    "        text_to_speech(\"Give the passage you want to ask questions from\", output_file)\n",
    "        play_mp3(output_file)\n",
    "        self.passage = input(\"Enter the Passage: \")\n",
    "\n",
    "    def generate_answer(self, question):\n",
    "        # Use self.passage and question to generate the answer\n",
    "        # Your question answering model implementation here\n",
    "        # Replace the return statement with your own answer generation logic\n",
    "        \n",
    "        return \"Answer to the question\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
